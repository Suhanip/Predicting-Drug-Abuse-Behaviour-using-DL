{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minor_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVC53H8NWVUe",
        "colab_type": "code",
        "outputId": "ed2e4726-f4cb-4587-b8d5-dae89b5f0d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "! pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.13.13)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.16.13)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0nSstA1We9O",
        "colab_type": "code",
        "outputId": "c6a7feea-77fb-4cf9-dd00-d6790ee6e426",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9c749a83-ca7b-44b2-9bb6-ad29f9b6cbcf\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9c749a83-ca7b-44b2-9bb6-ad29f9b6cbcf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving new_bow.txt to new_bow.txt\n",
            "Saving summary2.txt to summary2.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4nM6HNx2jva",
        "colab_type": "code",
        "outputId": "9939c954-d687-4e18-f687-0d2aa139f290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "#for importing csv file to which thw similarity values are going to be stored\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M7tpVNxW8uT",
        "colab_type": "code",
        "outputId": "0ce89ad0-d9a9-49e2-b020-af67f91523ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "%matplotlib\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_pretrained_bert import BertTokenizer,BertModel,BertForMaskedLM\n",
        "import logging\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using matplotlib backend: agg\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiWXLa4FX4qD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file1 = \"summary2.txt\"\n",
        "data1 = uploaded[file1].decode(\"utf-8\").split(\"\\r\\n\")\n",
        "\n",
        "for i in range(len(data1)):\n",
        "  data1[i] = data1[i].split(\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U_oEIHtY_Iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file3 = \"new_bow.txt\"\n",
        "data3 = uploaded[file3].decode(\"utf-8\").split(\"\\r\\n\")\n",
        "\n",
        "for i in range(len(data3)):\n",
        "  data3[i] = data3[i].split(\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wIPDClFmjnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Average(lst): \n",
        "    return sum(lst) / len(lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSOi7ZJGZe7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13866429-60bf-4a15-bdc9-0f0d695fbee0"
      },
      "source": [
        "list4 = []\n",
        "#loop for the tweet.txt files containing 10 lines having 15 tokens each.\n",
        "for i in data1:\n",
        "  for j in i:    \n",
        "    list3 = []\n",
        "    #input formatting\n",
        "    marked_text = \"[CLS]\"+j+\"[SEP]\"\n",
        "    #tokenization\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    #printing the tokens with their indices\n",
        "    for tup in zip(tokenized_text,indexed_tokens):\n",
        "      print('{:<12} {:>6}'.format(tup[0],tup[1]))\n",
        "    segment_ids = [1] * len(tokenized_text)\n",
        "    #converting python list to tensors as we are using pytorch and tensorflow code\n",
        "    token_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segment_ids])\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "    model.eval()\n",
        "    #Hidden states\n",
        "    with torch.no_grad():\n",
        "      encoded_layers, _ = model(token_tensor,segments_tensors)\n",
        "    print (\"Number of layers:\", len(encoded_layers))\n",
        "    layer_i = 0\n",
        "\n",
        "    print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "    batch_i = 0\n",
        "\n",
        "    print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "    token_i = 0\n",
        "\n",
        "    print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))\n",
        "\n",
        "    token_i = 5\n",
        "    layer_i = 5\n",
        "    vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "    #\n",
        "    token_vecs = encoded_layers[11][0]\n",
        "\n",
        "    # Calculate the average of all token vectors.\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "\n",
        "    #loop for the bag of words\n",
        "    for v in data3:\n",
        "      for u in v:\n",
        "        marked_text2 = \"[CLS]\"+u+\"[SEP]\"\n",
        "        tokenized_text2 = tokenizer.tokenize(marked_text2)\n",
        "        indexed_tokens2 = tokenizer.convert_tokens_to_ids(tokenized_text2)\n",
        "        segment_ids2 = [1] * len(tokenized_text2)\n",
        "        token_tensor2 = torch.tensor([indexed_tokens2])\n",
        "        segments_tensors2 = torch.tensor([segment_ids2])\n",
        "        model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        with torch.no_grad():\n",
        "          encoded_layers, _ = model(token_tensor2,segments_tensors2)\n",
        "        layer_i = 0\n",
        "\n",
        "        batch_i = 0\n",
        "\n",
        "        token_i = 0\n",
        "\n",
        "\n",
        "        token_i = 5\n",
        "        layer_i = 5\n",
        "        vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "        token_vecs2 = encoded_layers[11][0]\n",
        "\n",
        "        sentence_embedding2 = torch.mean(token_vecs2, dim=0)\n",
        "        \n",
        "        #finding the cosine similarity of the sentence embeddings of the pair of sentences\n",
        "        sen1_sen3_similarity =  cosine_similarity(sentence_embedding.reshape(1,-1),sentence_embedding2.reshape(1,-1))\n",
        "        list3.append(sen1_sen3_similarity)\n",
        "    average1 = Average(list3) #finding the average for calculating single similarity index\n",
        "    list4.append(average1)    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "smoke          5610\n",
            "read           3191\n",
            "educate       16957\n",
            "weed          17901\n",
            "illegal        6206\n",
            "lil           13451\n",
            "know           2113\n",
            "your           2115\n",
            "##e            2063\n",
            "scar          11228\n",
            "stone          2962\n",
            "high           2152\n",
            "pay            3477\n",
            "chan           9212\n",
            "##c            2278\n",
            "baby           3336\n",
            "believe        2903\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 24\n",
            "Number of hidden units: 768\n",
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "gunn          22079\n",
            "##a            2050\n",
            "weed          17901\n",
            "lil           13451\n",
            "tonight        3892\n",
            "drop           4530\n",
            "different      2367\n",
            "now            2085\n",
            "##play        13068\n",
            "##ing          2075\n",
            "red            2417\n",
            "albums         4042\n",
            "notes          3964\n",
            "new            2047\n",
            "flu           19857\n",
            "##kota        27380\n",
            "conditional   18462\n",
            "form           2433\n",
            "##you         29337\n",
            "##ng           3070\n",
            "wu             8814\n",
            "##nna          9516\n",
            "##the         10760\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 30\n",
            "Number of hidden units: 768\n",
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "people         2111\n",
            "un             4895\n",
            "##fo          14876\n",
            "##llo          7174\n",
            "##wed         15557\n",
            "follow         3582\n",
            "dozens         9877\n",
            "check          4638\n",
            "automatically   8073\n",
            "way            2126\n",
            "hang           6865\n",
            "##overs       24302\n",
            "instead        2612\n",
            "tell           2425\n",
            "alcoholic     14813\n",
            "##s            2015\n",
            "smoke          5610\n",
            "weed          17901\n",
            "god            2643\n",
            "girl           2611\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 27\n",
            "Number of hidden units: 768\n",
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "album          2201\n",
            "baby           3336\n",
            "lil           13451\n",
            "bad            2919\n",
            "high           2152\n",
            "right          2157\n",
            "eat            4521\n",
            "mixtape       18713\n",
            "heartbeat     12251\n",
            "energy         2943\n",
            "sneak         13583\n",
            "##y            2100\n",
            "notice         5060\n",
            "weird          6881\n",
            "shit           4485\n",
            "vibe          21209\n",
            "##s            2015\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 24\n",
            "Number of hidden units: 768\n",
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "like           2066\n",
            "high           2152\n",
            "amp           23713\n",
            "ric           26220\n",
            "##ch           2818\n",
            "rod            8473\n",
            "##dy           5149\n",
            "new            2047\n",
            "good           2204\n",
            "weed          17901\n",
            "ladies         6456\n",
            "head           2132\n",
            "videos         6876\n",
            "turn           2735\n",
            "stand          3233\n",
            "lips           2970\n",
            "lick          15385\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 24\n",
            "Number of hidden units: 768\n",
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "weed          17901\n",
            "legend         5722\n",
            "feel           2514\n",
            "birth          4182\n",
            "february       2337\n",
            "january        2254\n",
            "march          2233\n",
            "month          3204\n",
            "wee           16776\n",
            "weed          17901\n",
            "##ap           9331\n",
            "##ril         15928\n",
            "better         2488\n",
            "sad            6517\n",
            "ref           25416\n",
            "di             4487\n",
            "##za           4143\n",
            "##pa           4502\n",
            "##m            2213\n",
            "em             7861\n",
            "##zo           6844\n",
            "##r            2099\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 29\n",
            "Number of hidden units: 768\n",
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "high           2152\n",
            "weed          17901\n",
            "smoke          5610\n",
            "house          2160\n",
            "effort         3947\n",
            "mind           2568\n",
            "literally      6719\n",
            "damn           4365\n",
            "business       2449\n",
            "zero           5717\n",
            "wait           3524\n",
            "whip          11473\n",
            "jaw            5730\n",
            "##n            2078\n",
            "old            2214\n",
            "tell           2425\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 23\n",
            "Number of hidden units: 768\n",
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "smoke          5610\n",
            "weed          17901\n",
            "like           2066\n",
            "don            2123\n",
            "##t            2102\n",
            "high           2152\n",
            "need           2342\n",
            "people         2111\n",
            "cum           13988\n",
            "happy          3407\n",
            "wait           3524\n",
            "understand     3305\n",
            "edible        21006\n",
            "stone          2962\n",
            "##r            2099\n",
            "guy            3124\n",
            "kick           5926\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 24\n",
            "Number of hidden units: 768\n",
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "birthday       5798\n",
            "happy          3407\n",
            "like           2066\n",
            "joint          4101\n",
            "wins           5222\n",
            "##sta          9153\n",
            "##y            2100\n",
            "lift           6336\n",
            "person         2711\n",
            "lifted         4196\n",
            "mm             3461\n",
            "##em           6633\n",
            "##ber          5677\n",
            "##ville        3077\n",
            "day            2154\n",
            "smell          5437\n",
            "pills         15345\n",
            "hate           5223\n",
            "stay           2994\n",
            "love           2293\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 27\n",
            "Number of hidden units: 768\n",
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "de             2139\n",
            "##y            2100\n",
            "god            2643\n",
            "add            5587\n",
            "box            3482\n",
            "press          2811\n",
            "cr            13675\n",
            "##ave         10696\n",
            "brain          4167\n",
            "things         2477\n",
            "young          2402\n",
            "weed          17901\n",
            "##fo          14876\n",
            "##od           7716\n",
            "##water        5880\n",
            "##sle         25016\n",
            "##ep          13699\n",
            "##mon          8202\n",
            "##ey           3240\n",
            "need           2342\n",
            "mig           19117\n",
            "##os           2891\n",
            "good           2204\n",
            "broke          3631\n",
            "boy            2879\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 32\n",
            "Number of hidden units: 768\n",
            "[              1031\n",
            "cl            18856\n",
            "##s            2015\n",
            "]              1033\n",
            "[              1031\n",
            "sep           19802\n",
            "]              1033\n",
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 7\n",
            "Number of hidden units: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCzmC4cpdoNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#exporting the values of similarity indices to csv files\n",
        "import csv\n",
        "with open('/content/drive/My Drive/tweets1.csv', 'w') as f:\n",
        "  fi = csv.writer(f, quoting = csv.QUOTE_ALL)\n",
        "  fi.writerow(list4)\n",
        "!cat /content/drive/My\\ Drive/tweets1.csv\n",
        "files.download('/content/drive/My Drive/tweets1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ5wqNRWai3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}